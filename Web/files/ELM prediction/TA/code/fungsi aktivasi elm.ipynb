{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AKTIFASI FUNGSI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELU \n",
    "def relu(x):  # hidden layer activation function\n",
    "    return np.maximum(x, 0, x)\n",
    "\n",
    "\n",
    "def hidden_nodes(X):\n",
    "    G = np.dot(X, input_weights)\n",
    "    G = G + biases\n",
    "    H = relu(G)\n",
    "    return H\n",
    "\n",
    "\n",
    "output_weights = np.dot(pinv(hidden_nodes(X_train)), y_train)\n",
    "\n",
    "\n",
    "def predict(X):\n",
    "    out = hidden_nodes(X)\n",
    "    out = np.dot(out, output_weights)\n",
    "    return out\n",
    "\n",
    "\n",
    "prediction_train = predict(X_train)\n",
    "prediction_test = predict(X_test)\n",
    "\n",
    "\n",
    "# sigmoid \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def hidden_nodes(X):\n",
    "    G = np.dot(X, input_weights)\n",
    "    G = G + biases\n",
    "    H = sigmoid(G)  # Replace relu() with sigmoid()\n",
    "    return H\n",
    "\n",
    "output_weights = np.dot(pinv(hidden_nodes(X_train)), y_train)\n",
    "\n",
    "def predict(X):\n",
    "    out = hidden_nodes(X)\n",
    "    out = np.dot(out, output_weights)\n",
    "    return out\n",
    "\n",
    "prediction_train = predict(X_train)\n",
    "prediction_test = predict(X_test)\n",
    "\n",
    "# TANH\n",
    "\n",
    "def tanh(x):  # hidden layer activation function\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def hidden_nodes(X):\n",
    "    G = np.dot(X, input_weights)\n",
    "    G = G + biases\n",
    "    H = tanh(G)\n",
    "    return H\n",
    "\n",
    "\n",
    "output_weights = np.dot(pinv(hidden_nodes(X_train)), y_train)\n",
    "\n",
    "\n",
    "def predict(X):\n",
    "    out = hidden_nodes(X)\n",
    "    out = np.dot(out, output_weights)\n",
    "    return out\n",
    "\n",
    "\n",
    "prediction_train = predict(X_train)\n",
    "prediction_test = predict(X_test)\n",
    "\n",
    "#Exponential Linear Unit \n",
    "def elu(x):  # hidden layer activation function\n",
    "    alpha = 1.0  # Parameter determining the negative saturation point\n",
    "    return np.where(x >= 0, x, alpha * (np.exp(x) - 1))\n",
    "\n",
    "def hidden_nodes(X):\n",
    "    G = np.dot(X, input_weights)\n",
    "    G = G + biases\n",
    "    H = elu(G)  # Use ELU activation function instead of ReLU\n",
    "    return H\n",
    "\n",
    "# Rest of the code remains the same\n",
    "output_weights = np.dot(pinv(hidden_nodes(X_train)), y_train)\n",
    "\n",
    "def predict(X):\n",
    "    out = hidden_nodes(X)\n",
    "    out = np.dot(out, output_weights)\n",
    "    return out\n",
    "\n",
    "prediction_train = predict(X_train)\n",
    "prediction_test = predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
